{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Q&A application using Knowledge Bases for Amazon Bedrock - Retrieve API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This lab uses Anthropic Claude v3, which is not available in AWS Workshop Studio yet. You may\n",
    "    continue with this lab if the account you are running this in has access to Claude V3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "In this notebook, we will dive deep into building Q&A application using Knowledge Bases for Amazon Bedrock - Retrieve API. Here, we will query the knowledge base to get the desired number of document chunks based on similarity search. We will then augment the prompt with relevant documents and query which will go as input to Anthropic Claude V2 for generating response.\n",
    "\n",
    "With a knowledge base, you can securely connect foundation models (FMs) in Amazon Bedrock to your company\n",
    "data for Retrieval Augmented Generation (RAG). Access to additional data helps the model generate more relevant,\n",
    "context-speciﬁc, and accurate responses without continuously retraining the FM. All information retrieved from\n",
    "knowledge bases comes with source attribution to improve transparency and minimize hallucinations. For more information on creating a knowledge base using console, please refer to this [post](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html).\n",
    "We will cover 2 parts in the notebook:\n",
    "- Part 1, we will share how you can use `RetrieveAPI` with foundation models from Amazon Bedrock. We will use the `anthropic.claude-3-sonnet-20240229-v1:0` model. \n",
    "- Part 2, we will showcase the langchain integration.\n",
    "\n",
    "### Pattern\n",
    "\n",
    "We can implement the solution using Retreival Augmented Generation (RAG) pattern. RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. Here, we are performing RAG effectively on the knowledge base created using console/sdk. \n",
    "\n",
    "### Pre-requisite\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and ingested in vector database.\n",
    "\n",
    "1. Load the documents into the knowledge base by connecting your s3 bucket (data source). \n",
    "2. Ingestion - Knowledge bases will split them into smaller chunks (based on the strategy selected), generate embeddings and store it in the associated vectore store and notebook [0_create_ingest_documents_test_kb.ipynb](./0\\_create_ingest_documents_test_kb.ipynb) takes care of it for you.\n",
    "\n",
    "![data_ingestion](./images/data_ingestion.png)\n",
    "\n",
    "\n",
    "#### Notebook Walkthrough\n",
    "\n",
    "\n",
    "\n",
    "For our notebook we will use the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. \n",
    "\n",
    "\n",
    "We will then use the text chunks being generated and augment it with the original prompt and pass it through the `anthropic.claude-3-sonnet-20240229-v1:0` model using prompt engineering patterns based on your use case.\n",
    "    \n",
    "\n",
    "### USE CASE:\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on. This data is already ingested into the Knowledge Bases for Amazon Bedrock. You will need the `knowledge base id` to run this example.\n",
    "In your specific use case, you can sync different files for different domain topics and query this notebook in the same manner to evaluate model responses using the retrieve API from knowledge bases.\n",
    "\n",
    "\n",
    "### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "If you carry out the workshop from your local environment outside of the Amazon SageMaker studio please make sure you are running a Python runtime > 3.10.\n",
    "\n",
    "### Setup\n",
    "\n",
    "To run this notebook you would need to install following packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U langchain-aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart the kernel with the updated packages that are installed through the dependencies above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the steps below to initiate the bedrock client:\n",
    "\n",
    "1. Import the necessary libraries, along with langchain for bedrock model selection, llama index to store the service context containing the llm and embedding model instances. We will use this service context later in the notebook for evaluating the responses from our Q&A application. \n",
    "\n",
    "2. Initialize `anthropic.claude-3-sonnet-20240229-v1:0` as our large language model to perform query completions using the RAG pattern with the given knowledge base, once we get all text chunk searches through the `retrieve` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "import json\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config, region_name = region)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Retrieve API with foundation models from Amazon Bedrock\n",
    "\n",
    "Define a retrieve function that calls the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. You can also use the  `overrideSearchType` option in `retrievalConfiguration` which offers the choice to use either `HYBRID` or `SEMANTIC`. By default, it will select the right strategy for you to give you most relevant results, and if you want to override the default option to use either hybrid or semantic search, you can set the value to `HYBRID/SEMANTIC`.\n",
    "\n",
    "![retrieveAPI](./images/retrieveAPI.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize your Knowledge base id before querying responses from the initialized LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will call the `retreive API`, and pass `knowledge base id`, `number of results` and `query` as paramters. \n",
    "\n",
    "`score`: You can view the associated score of each of the text chunk that was returned which depicts its correlation to the query in terms of how closely it matches it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'Amazon has been using machine learning extensively '\n",
      "                         'for 25 years, employing it in everything from '\n",
      "                         'personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption. Generative AI '\n",
      "                         'is based on very Large Language Models (trained on '\n",
      "                         'up to hundreds of billions of parameters, and '\n",
      "                         'growing), across expansive datasets, and has '\n",
      "                         'radically general and broad recall and learning '\n",
      "                         'capabilities. We have been working on our own LLMs '\n",
      "                         'for a while now, believe it will transform and '\n",
      "                         'improve virtually every customer experience, and '\n",
      "                         'will continue to invest substantially in these '\n",
      "                         'models across all of our consumer, seller, brand, '\n",
      "                         'and creator experiences. Additionally, as we’ve done '\n",
      "                         'for years in AWS, we’re democratizing this '\n",
      "                         'technology so companies of all sizes can leverage '\n",
      "                         'Generative AI. AWS is offering the most '\n",
      "                         'price-performant machine learning chips in Trainium '\n",
      "                         'and Inferentia so small and large companies can '\n",
      "                         'afford to train and run their LLMs in production. We '\n",
      "                         'enable companies to choose from various LLMs and '\n",
      "                         'build applications with all of the AWS security, '\n",
      "                         'privacy and other features that customers are '\n",
      "                         'accustomed to using. And, we’re delivering '\n",
      "                         'applications like AWS’s CodeWhisperer, which '\n",
      "                         'revolutionizes        developer productivity by '\n",
      "                         'generating code suggestions in real time. I could '\n",
      "                         'write an entire letter on LLMs and Generative AI as '\n",
      "                         'I think they will be that transformative, but I’ll '\n",
      "                         'leave that for a future letter. Let’s just say that '\n",
      "                         'LLMs and Generative AI are going to be a big deal '\n",
      "                         'for customers, our shareholders, and Amazon.   So, '\n",
      "                         'in closing, I’m optimistic that we’ll emerge from '\n",
      "                         'this challenging macroeconomic time in a stronger '\n",
      "                         'position than when we entered it. There are several '\n",
      "                         'reasons for it and I’ve mentioned many of them '\n",
      "                         'above. But, there are two relatively simple '\n",
      "                         'statistics that underline our immense future '\n",
      "                         'opportunity. While we have a consumer business '\n",
      "                         'that’s $434B in 2022, the vast majority of total '\n",
      "                         'market segment share in global retail still resides '\n",
      "                         'in physical stores (roughly 80%). And, it’s a '\n",
      "                         'similar story for Global IT spending, where we have '\n",
      "                         'AWS revenue of $80B in 2022, with about 90% of '\n",
      "                         'Global IT spending still on-premises and yet to '\n",
      "                         'migrate to the cloud.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A2u5VHpIBnk0M5gezq8_A',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.67195415},\n",
      "  { 'content': { 'text': 'Imagine what they’ll be able to do with reliable '\n",
      "                         'connectivity, from people taking online education '\n",
      "                         'courses, using financial services, starting their '\n",
      "                         'own businesses, doing their shopping, enjoying '\n",
      "                         'entertainment, to businesses and governments '\n",
      "                         'improving their coverage, efficiency, and '\n",
      "                         'operations. Kuiper will deliver not only '\n",
      "                         'accessibility, but affordability. Our teams have '\n",
      "                         'developed low-cost antennas (i.e. customer '\n",
      "                         'terminals) that will lower the barriers to access. '\n",
      "                         'We recently unveiled the new terminals that will '\n",
      "                         'communicate with the satellites passing overhead, '\n",
      "                         'and we expect to be able to produce our standard '\n",
      "                         'residential version for less than $400 each. They’re '\n",
      "                         'small: 11 inches square, 1 inch thick, and weigh '\n",
      "                         'less than 5 pounds without their mounting bracket, '\n",
      "                         'but they deliver speeds up to 400 megabits per '\n",
      "                         'second. And they’re powered by Amazon-designed '\n",
      "                         'baseband chips. We’re preparing to launch two '\n",
      "                         'prototype satellites to test the entire end-to-end '\n",
      "                         'communications network this year, and plan to be in '\n",
      "                         'beta with commercial customers in 2024. The customer '\n",
      "                         'reaction to what we’ve shared thus far about Kuiper '\n",
      "                         'has been very positive, and we believe Kuiper '\n",
      "                         'represents a very large potential opportunity for '\n",
      "                         'Amazon. It also shares several similarities to AWS '\n",
      "                         'in that it’s capital intensive at the start, but has '\n",
      "                         'a large prospective consumer, enterprise, and '\n",
      "                         'government customer base, significant revenue and '\n",
      "                         'operating profit potential, and relatively few '\n",
      "                         'companies with the technical and inventive aptitude, '\n",
      "                         'as well as the investment hypothesis to go after '\n",
      "                         'it.   One final investment area that I’ll mention, '\n",
      "                         'that’s core to setting Amazon up to invent in every '\n",
      "                         'area of our business for many decades to come, and '\n",
      "                         'where we’re investing heavily is Large Language '\n",
      "                         'Models (“LLMs”) and Generative AI. Machine learning '\n",
      "                         'has been a technology with high promise for several '\n",
      "                         'decades, but it’s only been the last five to ten '\n",
      "                         'years that it’s started to be used more pervasively '\n",
      "                         'by companies. This shift was driven by several '\n",
      "                         'factors, including access to higher volumes of '\n",
      "                         'compute capacity at lower prices than was ever '\n",
      "                         'available. Amazon has been using machine learning '\n",
      "                         'extensively for 25 years, employing it in everything '\n",
      "                         'from personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A2e5VHpIBnk0M5gezq8_A',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.6654588229217324},\n",
      "  { 'content': { 'text': 'Our Inferentia2 chip, which just launched, offers up '\n",
      "                         'to four times higher throughput and ten times lower '\n",
      "                         'latency than our first Inferentia processor. With '\n",
      "                         'the enormous upcoming growth in machine learning, '\n",
      "                         'customers will be able to get a lot more done with '\n",
      "                         'AWS’s training and inference chips at a '\n",
      "                         'significantly lower cost. We’re not close to being '\n",
      "                         'done innovating here, and this long-term investment '\n",
      "                         'should prove fruitful for both customers and AWS. '\n",
      "                         'AWS is still in the early stages of its evolution, '\n",
      "                         'and has a chance for unusual growth in the next '\n",
      "                         'decade.   Similarly high potential, Amazon’s '\n",
      "                         'Advertising business is uniquely effective for '\n",
      "                         'brands, which is part of why it continues to grow at '\n",
      "                         'a brisk clip. Akin to physical retailers’ '\n",
      "                         'advertising businesses selling shelf space, end- '\n",
      "                         'caps, and placement in their circulars, our '\n",
      "                         'sponsored products and brands offerings have been an '\n",
      "                         'integral part        of the Amazon shopping '\n",
      "                         'experience for more than a decade. However, unlike '\n",
      "                         'physical retailers, Amazon can tailor these '\n",
      "                         'sponsored products to be relevant to what customers '\n",
      "                         'are searching for given what we know about shopping '\n",
      "                         'behaviors and our very deep investment in machine '\n",
      "                         'learning algorithms. This leads to advertising '\n",
      "                         'that’s more useful for customers; and as a result, '\n",
      "                         'performs better for brands. This is part of why our '\n",
      "                         'Advertising revenue has continued to grow rapidly '\n",
      "                         '(23% YoY in Q4 2022, 25% YoY overall for 2022 on a '\n",
      "                         '$31B revenue base), even as most large '\n",
      "                         'advertising-focused businesses’ growth have slowed '\n",
      "                         'over the last several quarters.   We strive to be '\n",
      "                         'the best place for advertisers to build their '\n",
      "                         'brands. We have near and long-term opportunities '\n",
      "                         'that will help us achieve that mission. We’re '\n",
      "                         'continuing to make large investments in machine '\n",
      "                         'learning to keep honing our advertising selection '\n",
      "                         'algorithms. For the past couple of years, we’ve '\n",
      "                         'invested in building comprehensive, flexible, and '\n",
      "                         'durable planning and measurement solutions, giving '\n",
      "                         'marketers greater insight into advertising '\n",
      "                         'effectiveness. An example is Amazon Marketing Cloud '\n",
      "                         '(“AMC”). AMC is a “clean room” (i.e. secure digital '\n",
      "                         'environment) in which advertisers can run custom '\n",
      "                         'audience and campaign analytics across a range of '\n",
      "                         'first and third-party inputs, in a privacy-safe '\n",
      "                         'manner, to generate advertising and business '\n",
      "                         'insights to inform their broader marketing and sales '\n",
      "                         'strategies. The Advertising and AWS teams have '\n",
      "                         'collaborated to enable companies to store their data '\n",
      "                         'in AWS, operate securely in AMC with Amazon and '\n",
      "                         'other third-party data sources, perform analytics in '\n",
      "                         'AWS, and have the option to activate advertising on '\n",
      "                         'Amazon or third-party publishers through the Amazon '\n",
      "                         'Demand-Side Platform.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A0-5VHpIBnk0M5gezq8_A',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.54837483},\n",
      "  { 'content': { 'text': 'We believe that we’ve only scratched the surface of '\n",
      "                         'what’s possible to date, and plan to keep building '\n",
      "                         'the features our business customers tell us they '\n",
      "                         'need and want.   While many brands and merchants '\n",
      "                         'successfully sell their products on Amazon’s '\n",
      "                         'marketplace, there are also a large number of brands '\n",
      "                         'and sellers who have launched their own '\n",
      "                         'direct-to-consumer websites. One of the challenges '\n",
      "                         'for these merchants is driving conversion from views '\n",
      "                         'to purchases. We invented Buy with Prime to help '\n",
      "                         'with this challenge. Buy with Prime allows '\n",
      "                         'third-party brands and sellers to offer their '\n",
      "                         'products on their own websites to our large Amazon '\n",
      "                         'Prime membership, and offer those customers fast, '\n",
      "                         'free Prime shipping and seamless checkout with their '\n",
      "                         'Amazon account. Buy with Prime provides merchants '\n",
      "                         'several additional benefits, including Amazon '\n",
      "                         'handling the product storage, picking, packing, '\n",
      "                         'delivery, payment, and any returns, all through '\n",
      "                         'Amazon Pay and Fulfillment by Amazon. Buy with Prime '\n",
      "                         'has recently been made available to all US '\n",
      "                         'merchants; and so far, Buy with Prime has increased '\n",
      "                         'shopper conversion on third-party shopping sites by '\n",
      "                         '25% on average. Merchants are excited about '\n",
      "                         'converting more sales and fulfilling these shipments '\n",
      "                         'more easily, Prime members love that they can use '\n",
      "                         'their Prime benefits on more destinations, and Buy '\n",
      "                         'with Prime allows us to improve the shopping '\n",
      "                         'experience across more of the web.   Expanding '\n",
      "                         'internationally, pursuing large retail market '\n",
      "                         'segments that are still nascent for Amazon, and '\n",
      "                         'using our unique assets to help merchants sell more '\n",
      "                         'effectively on their own websites are somewhat '\n",
      "                         'natural extensions for us. There are also a few '\n",
      "                         'investments we’re making that are further from our '\n",
      "                         'core businesses, but where we see unique '\n",
      "                         'opportunity. In 2003, AWS would have been a classic '\n",
      "                         'example. In 2023, Amazon Healthcare and Kuiper are '\n",
      "                         'potential analogues.   Our initial efforts in '\n",
      "                         'Healthcare began with pharmacy, which felt less like '\n",
      "                         'a major departure from ecommerce. For years, Amazon '\n",
      "                         'customers had asked us when we’d offer them an '\n",
      "                         'online pharmacy as their frustrations mounted with '\n",
      "                         'current providers. Launched in 2020, Amazon Pharmacy '\n",
      "                         'is a full-service, online pharmacy that offers '\n",
      "                         'transparent pricing, easy refills, and savings for '\n",
      "                         'Prime members. The business is growing quickly, and '\n",
      "                         'continues to innovate. An example is Amazon '\n",
      "                         'Pharmacy’s recent launch of RxPass, which for a $5 '\n",
      "                         'per        month flat fee, enables Prime members to '\n",
      "                         'get as many of the eligible prescription medications '\n",
      "                         'as they need for dozens of common conditions, like '\n",
      "                         'high blood pressure, acid reflux, and anxiety.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A1-5VHpIBnk0M5gezq8_A',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.5315453},\n",
      "  { 'content': { 'text': 'Amazon provides every full-time employee with health '\n",
      "                         'insurance, a 401(k) plan, 20 weeks paid maternity '\n",
      "                         'leave, and other benefits. These are the same '\n",
      "                         'benefits that Amazon’s most senior executives '\n",
      "                         'receive. And with our rapidly changing economy, we '\n",
      "                         'see more clearly than ever the need for workers to '\n",
      "                         'evolve their skills continually to keep up with '\n",
      "                         'technology. That’s why we’re spending $700 million '\n",
      "                         'to provide more than 100,000 Amazonians access to '\n",
      "                         'training programs, at their places of work, in '\n",
      "                         'high-demand fields such as healthcare, cloud '\n",
      "                         'computing, and machine learning. Since 2012, we have '\n",
      "                         'offered Career Choice, a pre-paid tuition program '\n",
      "                         'for fulfillment center associates looking to move '\n",
      "                         'into high- demand occupations. Amazon pays up to 95% '\n",
      "                         'of tuition and fees toward a certificate or diploma '\n",
      "                         'in qualified fields of study, leading to enhanced '\n",
      "                         'employment opportunities in high-demand jobs. Since '\n",
      "                         'its launch, more than 25,000 Amazonians have '\n",
      "                         'received training for in-demand occupations.   To '\n",
      "                         'ensure that future generations have the skills they '\n",
      "                         'need to thrive in a technology-driven economy, we '\n",
      "                         'started a program last year called Amazon Future '\n",
      "                         'Engineer, which is designed to educate and train '\n",
      "                         'low-income and disadvantaged young people to pursue '\n",
      "                         'careers in computer science. We have an ambitious '\n",
      "                         'goal: to help hundreds of thousands of students each '\n",
      "                         'year learn computer science and coding. Amazon '\n",
      "                         'Future Engineer currently funds Introduction to '\n",
      "                         'Computer Science and AP Computer Science classes for '\n",
      "                         'more than 2,000 schools in underserved communities '\n",
      "                         'across the country. Each year, Amazon Future '\n",
      "                         'Engineer also gives 100 four-year, $40,000 college '\n",
      "                         'scholarships to computer science students from '\n",
      "                         'low-income backgrounds. Those scholarship recipients '\n",
      "                         'also receive guaranteed, paid internships at Amazon '\n",
      "                         'after their first year of college. Our program in '\n",
      "                         'the UK funds 120 engineering apprenticeships and '\n",
      "                         'helps students from disadvantaged backgrounds pursue '\n",
      "                         'technology careers.   For now, my own time and '\n",
      "                         'thinking continues to be focused on COVID-19 and how '\n",
      "                         'Amazon can help while we’re in the middle of it. I '\n",
      "                         'am extremely grateful to my fellow Amazonians for '\n",
      "                         'all the grit and ingenuity they are showing as we '\n",
      "                         'move through this. You can count on all of us to '\n",
      "                         'look beyond the immediate crisis for insights and '\n",
      "                         'lessons and how to apply them going forward.   '\n",
      "                         'Reflect on this from Theodor Seuss Geisel:   “When '\n",
      "                         'something bad happens you have three choices. You '\n",
      "                         'can either let it define you, let it destroy you, or '\n",
      "                         'you can let it strengthen you.”   I am very '\n",
      "                         'optimistic about which of these civilization is '\n",
      "                         'going to choose.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2019-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A6e5VHpIBnk0M5gezrs_m',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2019-Shareholder-Letter.pdf'},\n",
      "    'score': 0.51453507}]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon doing in the field of Generative AI?\"\n",
    "kb_id =\"CET723VMXX\"\n",
    "response = retrieve(query, kb_id, 5)\n",
    "retrievalResults = response['retrievalResults']\n",
    "pp.pprint(retrievalResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the text chunks from the retrieveAPI response\n",
    "\n",
    "In the cell below, we will fetch the context from the retrieval results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch context from the response\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption. Generative AI is based on very Large Language Models '\n",
      "  '(trained on up to hundreds of billions of parameters, and growing), across '\n",
      "  'expansive datasets, and has radically general and broad recall and learning '\n",
      "  'capabilities. We have been working on our own LLMs for a while now, believe '\n",
      "  'it will transform and improve virtually every customer experience, and will '\n",
      "  'continue to invest substantially in these models across all of our '\n",
      "  'consumer, seller, brand, and creator experiences. Additionally, as we’ve '\n",
      "  'done for years in AWS, we’re democratizing this technology so companies of '\n",
      "  'all sizes can leverage Generative AI. AWS is offering the most '\n",
      "  'price-performant machine learning chips in Trainium and Inferentia so small '\n",
      "  'and large companies can afford to train and run their LLMs in production. '\n",
      "  'We enable companies to choose from various LLMs and build applications with '\n",
      "  'all of the AWS security, privacy and other features that customers are '\n",
      "  'accustomed to using. And, we’re delivering applications like AWS’s '\n",
      "  'CodeWhisperer, which revolutionizes        developer productivity by '\n",
      "  'generating code suggestions in real time. I could write an entire letter on '\n",
      "  'LLMs and Generative AI as I think they will be that transformative, but '\n",
      "  'I’ll leave that for a future letter. Let’s just say that LLMs and '\n",
      "  'Generative AI are going to be a big deal for customers, our shareholders, '\n",
      "  'and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this '\n",
      "  'challenging macroeconomic time in a stronger position than when we entered '\n",
      "  'it. There are several reasons for it and I’ve mentioned many of them above. '\n",
      "  'But, there are two relatively simple statistics that underline our immense '\n",
      "  'future opportunity. While we have a consumer business that’s $434B in 2022, '\n",
      "  'the vast majority of total market segment share in global retail still '\n",
      "  'resides in physical stores (roughly 80%). And, it’s a similar story for '\n",
      "  'Global IT spending, where we have AWS revenue of $80B in 2022, with about '\n",
      "  '90% of Global IT spending still on-premises and yet to migrate to the '\n",
      "  'cloud.',\n",
      "  'Imagine what they’ll be able to do with reliable connectivity, from people '\n",
      "  'taking online education courses, using financial services, starting their '\n",
      "  'own businesses, doing their shopping, enjoying entertainment, to businesses '\n",
      "  'and governments improving their coverage, efficiency, and operations. '\n",
      "  'Kuiper will deliver not only accessibility, but affordability. Our teams '\n",
      "  'have developed low-cost antennas (i.e. customer terminals) that will lower '\n",
      "  'the barriers to access. We recently unveiled the new terminals that will '\n",
      "  'communicate with the satellites passing overhead, and we expect to be able '\n",
      "  'to produce our standard residential version for less than $400 each. '\n",
      "  'They’re small: 11 inches square, 1 inch thick, and weigh less than 5 pounds '\n",
      "  'without their mounting bracket, but they deliver speeds up to 400 megabits '\n",
      "  'per second. And they’re powered by Amazon-designed baseband chips. We’re '\n",
      "  'preparing to launch two prototype satellites to test the entire end-to-end '\n",
      "  'communications network this year, and plan to be in beta with commercial '\n",
      "  'customers in 2024. The customer reaction to what we’ve shared thus far '\n",
      "  'about Kuiper has been very positive, and we believe Kuiper represents a '\n",
      "  'very large potential opportunity for Amazon. It also shares several '\n",
      "  'similarities to AWS in that it’s capital intensive at the start, but has a '\n",
      "  'large prospective consumer, enterprise, and government customer base, '\n",
      "  'significant revenue and operating profit potential, and relatively few '\n",
      "  'companies with the technical and inventive aptitude, as well as the '\n",
      "  'investment hypothesis to go after it.   One final investment area that I’ll '\n",
      "  'mention, that’s core to setting Amazon up to invent in every area of our '\n",
      "  'business for many decades to come, and where we’re investing heavily is '\n",
      "  'Large Language Models (“LLMs”) and Generative AI. Machine learning has been '\n",
      "  'a technology with high promise for several decades, but it’s only been the '\n",
      "  'last five to ten years that it’s started to be used more pervasively by '\n",
      "  'companies. This shift was driven by several factors, including access to '\n",
      "  'higher volumes of compute capacity at lower prices than was ever available. '\n",
      "  'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption.',\n",
      "  'Our Inferentia2 chip, which just launched, offers up to four times higher '\n",
      "  'throughput and ten times lower latency than our first Inferentia processor. '\n",
      "  'With the enormous upcoming growth in machine learning, customers will be '\n",
      "  'able to get a lot more done with AWS’s training and inference chips at a '\n",
      "  'significantly lower cost. We’re not close to being done innovating here, '\n",
      "  'and this long-term investment should prove fruitful for both customers and '\n",
      "  'AWS. AWS is still in the early stages of its evolution, and has a chance '\n",
      "  'for unusual growth in the next decade.   Similarly high potential, Amazon’s '\n",
      "  'Advertising business is uniquely effective for brands, which is part of why '\n",
      "  'it continues to grow at a brisk clip. Akin to physical retailers’ '\n",
      "  'advertising businesses selling shelf space, end- caps, and placement in '\n",
      "  'their circulars, our sponsored products and brands offerings have been an '\n",
      "  'integral part        of the Amazon shopping experience for more than a '\n",
      "  'decade. However, unlike physical retailers, Amazon can tailor these '\n",
      "  'sponsored products to be relevant to what customers are searching for given '\n",
      "  'what we know about shopping behaviors and our very deep investment in '\n",
      "  'machine learning algorithms. This leads to advertising that’s more useful '\n",
      "  'for customers; and as a result, performs better for brands. This is part of '\n",
      "  'why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 '\n",
      "  '2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large '\n",
      "  'advertising-focused businesses’ growth have slowed over the last several '\n",
      "  'quarters.   We strive to be the best place for advertisers to build their '\n",
      "  'brands. We have near and long-term opportunities that will help us achieve '\n",
      "  'that mission. We’re continuing to make large investments in machine '\n",
      "  'learning to keep honing our advertising selection algorithms. For the past '\n",
      "  'couple of years, we’ve invested in building comprehensive, flexible, and '\n",
      "  'durable planning and measurement solutions, giving marketers greater '\n",
      "  'insight into advertising effectiveness. An example is Amazon Marketing '\n",
      "  'Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in '\n",
      "  'which advertisers can run custom audience and campaign analytics across a '\n",
      "  'range of first and third-party inputs, in a privacy-safe manner, to '\n",
      "  'generate advertising and business insights to inform their broader '\n",
      "  'marketing and sales strategies. The Advertising and AWS teams have '\n",
      "  'collaborated to enable companies to store their data in AWS, operate '\n",
      "  'securely in AMC with Amazon and other third-party data sources, perform '\n",
      "  'analytics in AWS, and have the option to activate advertising on Amazon or '\n",
      "  'third-party publishers through the Amazon Demand-Side Platform.',\n",
      "  'We believe that we’ve only scratched the surface of what’s possible to '\n",
      "  'date, and plan to keep building the features our business customers tell us '\n",
      "  'they need and want.   While many brands and merchants successfully sell '\n",
      "  'their products on Amazon’s marketplace, there are also a large number of '\n",
      "  'brands and sellers who have launched their own direct-to-consumer websites. '\n",
      "  'One of the challenges for these merchants is driving conversion from views '\n",
      "  'to purchases. We invented Buy with Prime to help with this challenge. Buy '\n",
      "  'with Prime allows third-party brands and sellers to offer their products on '\n",
      "  'their own websites to our large Amazon Prime membership, and offer those '\n",
      "  'customers fast, free Prime shipping and seamless checkout with their Amazon '\n",
      "  'account. Buy with Prime provides merchants several additional benefits, '\n",
      "  'including Amazon handling the product storage, picking, packing, delivery, '\n",
      "  'payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. '\n",
      "  'Buy with Prime has recently been made available to all US merchants; and so '\n",
      "  'far, Buy with Prime has increased shopper conversion on third-party '\n",
      "  'shopping sites by 25% on average. Merchants are excited about converting '\n",
      "  'more sales and fulfilling these shipments more easily, Prime members love '\n",
      "  'that they can use their Prime benefits on more destinations, and Buy with '\n",
      "  'Prime allows us to improve the shopping experience across more of the '\n",
      "  'web.   Expanding internationally, pursuing large retail market segments '\n",
      "  'that are still nascent for Amazon, and using our unique assets to help '\n",
      "  'merchants sell more effectively on their own websites are somewhat natural '\n",
      "  'extensions for us. There are also a few investments we’re making that are '\n",
      "  'further from our core businesses, but where we see unique opportunity. In '\n",
      "  '2003, AWS would have been a classic example. In 2023, Amazon Healthcare and '\n",
      "  'Kuiper are potential analogues.   Our initial efforts in Healthcare began '\n",
      "  'with pharmacy, which felt less like a major departure from ecommerce. For '\n",
      "  'years, Amazon customers had asked us when we’d offer them an online '\n",
      "  'pharmacy as their frustrations mounted with current providers. Launched in '\n",
      "  '2020, Amazon Pharmacy is a full-service, online pharmacy that offers '\n",
      "  'transparent pricing, easy refills, and savings for Prime members. The '\n",
      "  'business is growing quickly, and continues to innovate. An example is '\n",
      "  'Amazon Pharmacy’s recent launch of RxPass, which for a $5 per        month '\n",
      "  'flat fee, enables Prime members to get as many of the eligible prescription '\n",
      "  'medications as they need for dozens of common conditions, like high blood '\n",
      "  'pressure, acid reflux, and anxiety.',\n",
      "  'Amazon provides every full-time employee with health insurance, a 401(k) '\n",
      "  'plan, 20 weeks paid maternity leave, and other benefits. These are the same '\n",
      "  'benefits that Amazon’s most senior executives receive. And with our rapidly '\n",
      "  'changing economy, we see more clearly than ever the need for workers to '\n",
      "  'evolve their skills continually to keep up with technology. That’s why '\n",
      "  'we’re spending $700 million to provide more than 100,000 Amazonians access '\n",
      "  'to training programs, at their places of work, in high-demand fields such '\n",
      "  'as healthcare, cloud computing, and machine learning. Since 2012, we have '\n",
      "  'offered Career Choice, a pre-paid tuition program for fulfillment center '\n",
      "  'associates looking to move into high- demand occupations. Amazon pays up to '\n",
      "  '95% of tuition and fees toward a certificate or diploma in qualified fields '\n",
      "  'of study, leading to enhanced employment opportunities in high-demand jobs. '\n",
      "  'Since its launch, more than 25,000 Amazonians have received training for '\n",
      "  'in-demand occupations.   To ensure that future generations have the skills '\n",
      "  'they need to thrive in a technology-driven economy, we started a program '\n",
      "  'last year called Amazon Future Engineer, which is designed to educate and '\n",
      "  'train low-income and disadvantaged young people to pursue careers in '\n",
      "  'computer science. We have an ambitious goal: to help hundreds of thousands '\n",
      "  'of students each year learn computer science and coding. Amazon Future '\n",
      "  'Engineer currently funds Introduction to Computer Science and AP Computer '\n",
      "  'Science classes for more than 2,000 schools in underserved communities '\n",
      "  'across the country. Each year, Amazon Future Engineer also gives 100 '\n",
      "  'four-year, $40,000 college scholarships to computer science students from '\n",
      "  'low-income backgrounds. Those scholarship recipients also receive '\n",
      "  'guaranteed, paid internships at Amazon after their first year of college. '\n",
      "  'Our program in the UK funds 120 engineering apprenticeships and helps '\n",
      "  'students from disadvantaged backgrounds pursue technology careers.   For '\n",
      "  'now, my own time and thinking continues to be focused on COVID-19 and how '\n",
      "  'Amazon can help while we’re in the middle of it. I am extremely grateful to '\n",
      "  'my fellow Amazonians for all the grit and ingenuity they are showing as we '\n",
      "  'move through this. You can count on all of us to look beyond the immediate '\n",
      "  'crisis for insights and lessons and how to apply them going forward.   '\n",
      "  'Reflect on this from Theodor Seuss Geisel:   “When something bad happens '\n",
      "  'you have three choices. You can either let it define you, let it destroy '\n",
      "  'you, or you can let it strengthen you.”   I am very optimistic about which '\n",
      "  'of these civilization is going to choose.']\n"
     ]
    }
   ],
   "source": [
    "contexts = get_contexts(retrievalResults)\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt specific to the model to personalize responses \n",
    "\n",
    "Here, we will use the specific prompt below for the model to act as a financial advisor AI system that will provide answers to questions by using fact based and statistical information when possible. We will provide the `Retrieve API` responses from above as a part of the `{contexts}` in the prompt for the model to refer to, along with the user `query`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Human: You are a financial advisor AI system, and provides answers to questions by using fact based and statistical information when possible. \n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{contexts}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke foundation model from Amazon Bedrock\n",
    "In this example, we will use `anthropic.claude-3-sonnet-20240229-v1:0` foundation model from Amazon Bedrock. \n",
    "- It offers maximum utility at a lower price than competitors, and is engineered to be the dependable, high-endurance workhorse for scaled AI deployments. Claude 3 Sonnet can process images and return text outputs, and features a 200K context window.\n",
    "- Model attributes\n",
    "    - Image to text & code, multilingual conversation, complex reasoning & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload with model paramters\n",
    "messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(contexts, query)}]}]\n",
    "sonnet_payload = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 1\n",
    "        }  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('According to the information provided, Amazon is heavily investing in Large '\n",
      " 'Language Models (LLMs) and Generative AI. Some key points:\\n'\n",
      " '\\n'\n",
      " '- Amazon has been working on its own LLMs for a while and believes '\n",
      " 'Generative AI will transform and improve virtually every customer experience '\n",
      " 'across its consumer, seller, brand, and creator experiences.\\n'\n",
      " '\\n'\n",
      " '- Amazon is democratizing this technology through AWS so that companies of '\n",
      " 'all sizes can leverage Generative AI. AWS offers highly performant and '\n",
      " 'cost-effective machine learning chips like Trainium and Inferentia to enable '\n",
      " 'training and running LLMs.\\n'\n",
      " '\\n'\n",
      " '- AWS provides applications like CodeWhisperer that use Generative AI to '\n",
      " 'revolutionize developer productivity by generating real-time code '\n",
      " 'suggestions.\\n'\n",
      " '\\n'\n",
      " '- The passage states \"I could write an entire letter on LLMs and Generative '\n",
      " 'AI as I think they will be that transformative\" indicating Amazon views this '\n",
      " 'as a major area of investment and focus.\\n'\n",
      " '\\n'\n",
      " '- However, no specific investment numbers or statistics are provided '\n",
      " \"regarding Amazon's spending or resources dedicated to Generative AI \"\n",
      " 'initiatives.')\n"
     ]
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "response = bedrock_client.invoke_model(body=sonnet_payload, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_text = response_body.get('content')[0]['text']\n",
    "\n",
    "pp.pprint(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - LangChain integration\n",
    "In this notebook, we will dive deep into building Q&A application using Retrieve API provided by Knowledge Bases for Amazon Bedrock and LangChain. We will query the knowledge base to get the desired number of document chunks based on similarity search, integrate it with LangChain retriever and use `Anthropic Claude 3 Sonnet` model for answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "llm = ChatBedrock(model_id=modelId, \n",
    "                  client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `AmazonKnowledgeBasesRetriever` object from LangChain which will call the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/jczxmthn3sv88zhk4c_3j9lh0000gs/T/ipykernel_70822/4125802233.py:13: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.67195415, 'source_metadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A2u5VHpIBnk0M5gezq8_A', 'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW'}}, page_content='Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. We have been working on our own LLMs for a while now, believe it will transform and improve virtually every customer experience, and will continue to invest substantially in these models across all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years in AWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia so small and large companies can afford to train and run their LLMs in production. We enable companies to choose from various LLMs and build applications with all of the AWS security, privacy and other features that customers are accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes        developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs and Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s just say that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger position than when we entered it. There are several reasons for it and I’ve mentioned many of them above. But, there are two relatively simple statistics that underline our immense future opportunity. While we have a consumer business that’s $434B in 2022, the vast majority of total market segment share in global retail still resides in physical stores (roughly 80%). And, it’s a similar story for Global IT spending, where we have AWS revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrate to the cloud.'),\n",
      "  Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.54837483, 'source_metadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A0-5VHpIBnk0M5gezq8_A', 'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW'}}, page_content='Our Inferentia2 chip, which just launched, offers up to four times higher throughput and ten times lower latency than our first Inferentia processor. With the enormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’s training and inference chips at a significantly lower cost. We’re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the early stages of its evolution, and has a chance for unusual growth in the next decade.   Similarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it continues to grow at a brisk clip. Akin to physical retailers’ advertising businesses selling shelf space, end- caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part        of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon can tailor these sponsored products to be relevant to what customers are searching for given what we know about shopping behaviors and our very deep investment in machine learning algorithms. This leads to advertising that’s more useful for customers; and as a result, performs better for brands. This is part of why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the last several quarters.   We strive to be the best place for advertisers to build their brands. We have near and long-term opportunities that will help us achieve that mission. We’re continuing to make large investments in machine learning to keep honing our advertising selection algorithms. For the past couple of years, we’ve invested in building comprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insight into advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in which advertisers can run custom audience and campaign analytics across a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and business insights to inform their broader marketing and sales strategies. The Advertising and AWS teams have collaborated to enable companies to store their data in AWS, operate securely in AMC with Amazon and other third-party data sources, perform analytics in AWS, and have the option to activate advertising on Amazon or third-party publishers through the Amazon Demand-Side Platform.'),\n",
      "  Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.5332557, 'source_metadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A2e5VHpIBnk0M5gezq8_A', 'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW'}}, page_content='Imagine what they’ll be able to do with reliable connectivity, from people taking online education courses, using financial services, starting their own businesses, doing their shopping, enjoying entertainment, to businesses and governments improving their coverage, efficiency, and operations. Kuiper will deliver not only accessibility, but affordability. Our teams have developed low-cost antennas (i.e. customer terminals) that will lower the barriers to access. We recently unveiled the new terminals that will communicate with the satellites passing overhead, and we expect to be able to produce our standard residential version for less than $400 each. They’re small: 11 inches square, 1 inch thick, and weigh less than 5 pounds without their mounting bracket, but they deliver speeds up to 400 megabits per second. And they’re powered by Amazon-designed baseband chips. We’re preparing to launch two prototype satellites to test the entire end-to-end communications network this year, and plan to be in beta with commercial customers in 2024. The customer reaction to what we’ve shared thus far about Kuiper has been very positive, and we believe Kuiper represents a very large potential opportunity for Amazon. It also shares several similarities to AWS in that it’s capital intensive at the start, but has a large prospective consumer, enterprise, and government customer base, significant revenue and operating profit potential, and relatively few companies with the technical and inventive aptitude, as well as the investment hypothesis to go after it.   One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”) and Generative AI. Machine learning has been a technology with high promise for several decades, but it’s only been the last five to ten years that it’s started to be used more pervasively by companies. This shift was driven by several factors, including access to higher volumes of compute capacity at lower prices than was ever available. Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption.'),\n",
      "  Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.5315453, 'source_metadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-153264177053/AMZN-2022-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A1-5VHpIBnk0M5gezq8_A', 'x-amz-bedrock-kb-data-source-id': 'IVD2HH00QW'}}, page_content='We believe that we’ve only scratched the surface of what’s possible to date, and plan to keep building the features our business customers tell us they need and want.   While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also a large number of brands and sellers who have launched their own direct-to-consumer websites. One of the challenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime to help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products on their own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shipping and seamless checkout with their Amazon account. Buy with Prime provides merchants several additional benefits, including Amazon handling the product storage, picking, packing, delivery, payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been made available to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-party shopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling these shipments more easily, Prime members love that they can use their Prime benefits on more destinations, and Buy with Prime allows us to improve the shopping experience across more of the web.   Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and using our unique assets to help merchants sell more effectively on their own websites are somewhat natural extensions for us. There are also a few investments we’re making that are further from our core businesses, but where we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, Amazon Healthcare and Kuiper are potential analogues.   Our initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce. For years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrations mounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members. The business is growing quickly, and continues to innovate. An example is Amazon Pharmacy’s recent launch of RxPass, which for a $5 per        month flat fee, enables Prime members to get as many of the eligible prescription medications as they need for dozens of common conditions, like high blood pressure, acid reflux, and anxiety.')]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon doing in the field of Generative AI?\"\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": \n",
    "                          {\"numberOfResults\": 4,\n",
    "                           'overrideSearchType': \"SEMANTIC\", # optional\n",
    "                           }\n",
    "                          },\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=region,\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )\n",
    "docs = retriever.get_relevant_documents(\n",
    "        query=query\n",
    "    )\n",
    "pp.pprint(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt specific to the model to personalize responses\n",
    "\n",
    "Here, we will use two helper functions to build the chain to invoke the model:\n",
    "- `create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. In this case, we will \"stuff\" the contents into the prompt -- i.e., we will include all retrieved context without any summarization or other processing. It largely implements our above rag_chain, with input keys context and input-- it generates an answer using retrieved context and query.\n",
    "- `create_retrieval_chain`  adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key input, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('According to the context provided, Amazon is investing significantly in '\n",
      " 'large language models (LLMs) and generative AI. Some key points:\\n'\n",
      " '\\n'\n",
      " '1. Amazon believes generative AI will transform and improve virtually every '\n",
      " 'customer experience, and is continuing to invest substantially in these '\n",
      " 'models across all of its consumer, seller, brand, and creator experiences.\\n'\n",
      " '\\n'\n",
      " '2. On AWS, Amazon is offering machine learning chips like Trainium and '\n",
      " 'Inferentia that allow companies of all sizes to affordably train and run '\n",
      " 'their own LLMs in production.\\n'\n",
      " '\\n'\n",
      " '3. AWS is enabling companies to choose from various LLMs and build '\n",
      " \"applications using AWS's security, privacy and other features.\\n\"\n",
      " '\\n'\n",
      " '4. AWS has already delivered applications like CodeWhisperer that use '\n",
      " 'generative AI to revolutionize developer productivity by generating code '\n",
      " 'suggestions in real time.\\n'\n",
      " '\\n'\n",
      " '5. The passage states that generative AI and LLMs are going to be a big deal '\n",
      " \"for Amazon's customers, shareholders, and the company itself.\\n\"\n",
      " '\\n'\n",
      " 'In summary, Amazon sees generative AI powered by large language models as a '\n",
      " 'transformative technology and is investing heavily across its consumer '\n",
      " 'businesses as well as providing services and infrastructure on AWS to '\n",
      " 'democratize this technology.')\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": query})\n",
    "pp.pprint(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You can use Retrieve API for customizing your RAG based application, using either `InvokeModel` API from Bedrock, or you can integrate with LangChain using `AmazonKnowledgeBaseRetriever`.\n",
    "Retrieve API provides you with the flexibility of using any foundation model provided by Amazon Bedrock, and choosing the right search type, either HYBRID or SEMANTIC, based on your use case. \n",
    "Here is the [blog](#https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-hybrid-search/) for Hybrid Search feature, for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
